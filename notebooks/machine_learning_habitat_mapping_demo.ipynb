{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict habitat for native species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import configuration and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eo_insights.stac_configuration import de_australia_stac_config\n",
    "from eo_insights.raster_base import RasterBase, QueryParams, LoadParams\n",
    "from eo_insights.band_indices import calculate_indices\n",
    "from rasterstats import zonal_stats\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from skimage.segmentation import quickshift,slic\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from eo_insights.spatial import xr_rasterize, xr_vectorize\n",
    "from affine import Affine\n",
    "from sklearn.model_selection import StratifiedKFold,cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data and define study area\n",
    "In this notebook We use filtered Bell Frog presence points from Atlas of Living Australia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative path of training data\n",
    "path_fauna_data=\"notebooks/data/native_species_data/records-2024-02-13-south-east-coastal-plain-southern-bell-frog_filtered_subset_small.geojson\"\n",
    "# load data\n",
    "cwd = Path().resolve()\n",
    "gdf_fauna=gpd.read_file(cwd.joinpath(path_fauna_data)).to_crs(\"EPSG:3577\")\n",
    "bbox=gdf_fauna.to_crs(\"EPSG:4326\").total_bounds\n",
    "gdf_fauna.explore(column='year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query satellite products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get DEA configuration and list collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = de_australia_stac_config\n",
    "config.list_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DEA products of most recent year:\n",
    "* Landsat 8 & 9 yearly geomedian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_params_ls = QueryParams(\n",
    "    bbox=bbox,\n",
    "    start_date=\"2023-01-01\",\n",
    "    end_date=\"2023-12-31\",\n",
    ")\n",
    "\n",
    "# Landsat 8 & 9 yearly geomedian: load only geomedian spectral bands for now\n",
    "params_ls_8_9_gm = LoadParams(\n",
    "    crs=\"EPSG:3577\",\n",
    "    resolution=30,\n",
    "    bands=(\"blue\", \"green\", \"red\", \"nir\", \"swir_1\", \"swir_2\"),\n",
    ")\n",
    "raster_ls_8_9_gm = RasterBase.from_stac_query(\n",
    "    config=config,\n",
    "    collections=[\"ga_ls8cls9c_gm_cyear_3\"],\n",
    "    query_params=query_params_ls,\n",
    "    load_params=params_ls_8_9_gm,\n",
    ")\n",
    "\n",
    "# calculate indices\n",
    "ds_ls_8_9_gm = calculate_indices(raster_ls_8_9_gm.data, [\"ndvi\",\"ndwi\"])\n",
    "\n",
    "ds_ls_8_9_gm= ds_ls_8_9_gm.isel(time=0)\n",
    "ds_ls_8_9_gm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sentinel-2 Barest Earth\n",
    "* Calculate BSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_params_s2_be = QueryParams(\n",
    "    bbox=bbox,\n",
    "    start_date=\"2017-01-01\",\n",
    "    end_date=\"2018-12-31\",\n",
    ")\n",
    "\n",
    "# load only bands that are used for BSI calculation\n",
    "params_s2_be = LoadParams(\n",
    "    crs=\"EPSG:3577\",\n",
    "    resolution=30,\n",
    "    bands=(\"blue\", \"red\", \"nir\", \"swir_1\"),\n",
    ")\n",
    "raster_s2_be = RasterBase.from_stac_query(\n",
    "    config=config,\n",
    "    collections=[\"s2_barest_earth\"],\n",
    "    query_params=query_params_s2_be,\n",
    "    load_params=params_s2_be,\n",
    ")\n",
    "\n",
    "# calculate BSI\n",
    "ds_s2_be_bsi = calculate_indices(raster_s2_be.data, [\"bsi\"])\n",
    "\n",
    "# dropping original bands\n",
    "ds_s2_be_bsi = ds_s2_be_bsi[[\"bsi\"]].isel(time=0)\n",
    "ds_s2_be_bsi\n",
    "# ds_s2_be_bsi['bsi'].plot.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SRTM 1 second DEM version 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_params_dem = QueryParams(\n",
    "    bbox=bbox,\n",
    "    start_date=\"2014-01-01\",\n",
    "    end_date=\"2014-12-31\",\n",
    ")\n",
    "\n",
    "params_dem = LoadParams(\n",
    "    crs=\"EPSG:3577\",\n",
    "    resolution=30,\n",
    "    bands=(\"dem\"),\n",
    ")\n",
    "raster_dem= RasterBase.from_stac_query(\n",
    "    config=config,\n",
    "    collections=[\"ga_srtm_dem1sv1_0\"],\n",
    "    query_params=query_params_dem,\n",
    "    load_params=params_dem,\n",
    ")\n",
    "ds_dem = raster_dem.data.isel(time=0)\n",
    "ds_dem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Multi-scale Topographic Position Index (TPI) layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_params_tpi = QueryParams(\n",
    "    bbox=bbox,\n",
    "    start_date=\"2018-01-01\",\n",
    "    end_date=\"2018-12-31\",\n",
    ")\n",
    "\n",
    "params_tpi = LoadParams(\n",
    "    crs=\"EPSG:3577\",\n",
    "    resolution=30,\n",
    "    bands=(\"regional\", \"intermediate\", \"local\"),\n",
    ")\n",
    "raster_tpi= RasterBase.from_stac_query(\n",
    "    config=config,\n",
    "    collections=[\"multi_scale_topographic_position\"],\n",
    "    query_params=query_params_tpi,\n",
    "    load_params=params_tpi,\n",
    ")\n",
    "ds_tip = raster_tpi.data.isel(time=0)\n",
    "ds_tip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Weathering Intensity layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_params_weathering = QueryParams(\n",
    "    bbox=bbox,\n",
    "    start_date=\"2018-01-01\",\n",
    "    end_date=\"2018-12-31\",\n",
    ")\n",
    "\n",
    "params_weathering = LoadParams(\n",
    "    crs=\"EPSG:3577\",\n",
    "    resolution=30,\n",
    "    bands=(\"intensity\"),\n",
    ")\n",
    "raster_weathering= RasterBase.from_stac_query(\n",
    "    config=config,\n",
    "    collections=[\"weathering_intensity\"],\n",
    "    query_params=query_params_weathering,\n",
    "    load_params=params_weathering,\n",
    ")\n",
    "ds_weathering = raster_weathering.data.isel(time=0)\n",
    "ds_weathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack all product bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all = xr.merge([ds_ls_8_9_gm, ds_s2_be_bsi, ds_dem, ds_tip, ds_weathering], compat='override').compute()\n",
    "ds_all.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object-based classification for species habitat prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_data=np.moveaxis(ds_all[['ndvi','ndwi','dem']].to_array().to_numpy(),0,-1)\n",
    "\n",
    "# feature normalisation\n",
    "rows,columns,n_band=arr_data.shape\n",
    "arr_data=np.reshape(arr_data,(rows*columns,n_band))\n",
    "arr_data = StandardScaler ().fit_transform(arr_data)\n",
    "\n",
    "# Do segmentation - slic or quickshift\n",
    "arr_data=np.reshape(arr_data,(rows,columns,n_band))\n",
    "# da_segments = slic(arr_data,n_segments=500,compactness=compactness,slic_zero=False)\n",
    "# da_segments = quickshift(arr_data,ratio=0.8,kernel_size=2,max_dist=10,sigma=0,convert2lab=False)\n",
    "da_segments = quickshift(arr_data,ratio=1.0,kernel_size=3,max_dist=10,sigma=0,convert2lab=False)\n",
    "da_segments = xr.DataArray(da_segments, coords=ds_all.coords, dims=ds_all.dims,\n",
    "                    attrs=ds_all.attrs).astype(np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorise segmentation raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_segments=xr_vectorize(da_segments).drop(['attribute'],axis=1)\n",
    "gdf_segments.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object-level features calculation through zonal statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names=list(ds_all.keys())\n",
    "list_stats=['median', 'std', 'percentile_10','percentile_90']\n",
    "transform = Affine.translation(float(da_segments.x.min()), float(da_segments.y.max())) * Affine.scale(30, -30)\n",
    "# transform = segments.rio.transform() # when rioxarray is available\n",
    "gdf_stats_all=None\n",
    "attr_fields=['geometry']\n",
    "\n",
    "# Calculate zonal statistics for all bands\n",
    "for var in var_names:\n",
    "\n",
    "    print('calculating zonal statistics for band',var)\n",
    "    band=ds_all[var].to_numpy()\n",
    "    zonestats=zonal_stats(gdf_segments, band, stats=list_stats, affine=transform, all_touched=True,geojson_out=True,)\n",
    "\n",
    "    # convert to geopandas dataframe\n",
    "    gdf_stats=gpd.GeoDataFrame.from_features(zonestats, crs=gdf_segments.crs)\n",
    "\n",
    "    # rename stats to use band name as prefix \n",
    "    for stat in list_stats:\n",
    "        stat_var=var+'_'+stat\n",
    "        gdf_stats.rename(columns={stat: stat_var}, inplace=True)\n",
    "        attr_fields.append(stat_var)\n",
    "\n",
    "    # append statistics\n",
    "    if gdf_stats_all is None:\n",
    "        gdf_stats_all=gdf_stats.copy()\n",
    "    else:\n",
    "        gdf_stats_all=pd.concat([gdf_stats_all,gdf_stats.drop(['geometry'],axis=1)],axis=1)\n",
    "\n",
    "# remove redundant attributes\n",
    "for column_name in list(gdf_stats.columns):\n",
    "    if column_name not in attr_fields:\n",
    "        gdf_stats_all.drop([column_name],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export zonal statistics as a vector file for reuse (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_stats_all.to_file(cwd.joinpath(\"notebooks/data/native_species_data/segmentation_stats.geojson\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field='Presence'\n",
    "n_absence=100\n",
    "\n",
    "# Get presence samples and pesudo-absence samples\n",
    "occurence_segs=gdf_stats_all[gdf_stats_all.intersects(gdf_fauna.unary_union)].reset_index(drop=True)\n",
    "absence_segs=pd.concat([gdf_stats_all,occurence_segs]).drop_duplicates(keep=False).sample(n=n_absence).reset_index(drop=True)\n",
    "\n",
    "# Presence samples labelled as 1; pesudo-absence samples labelled as 2\n",
    "occurence_segs[field]=1\n",
    "absence_segs[field]=2\n",
    "\n",
    "# Merge presence and absence samples\n",
    "train_segs=pd.concat([occurence_segs,absence_segs]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_segs=train_segs.drop(columns=['geometry'])\n",
    "column_names=train_segs.columns\n",
    "X = train_segs.iloc[:, 0:-1]\n",
    "y = train_segs.iloc[:, -1]\n",
    "Classifier = RandomForestClassifier(n_estimators=200)\n",
    "Classifier.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf=StratifiedKFold(n_splits=5,shuffle=True,random_state=1) # stratified K-fold splitting\n",
    "overall_acc=cross_val_score(Classifier,X,y,cv=skf,scoring='accuracy')\n",
    "print('Overall accuracy from cv scores: ',np.mean(overall_acc))\n",
    "f1_macro=cross_val_score(Classifier,X,y,cv=skf,scoring='f1_macro')\n",
    "print('f1_macro from cv scores: ',np.mean(f1_macro))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on all the study area\n",
    "Here we predict and display prediction probability of  Bell Frog along with training points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=Classifier.predict(gdf_stats_all[column_names[0:-1]].interpolate(method='nearest'))\n",
    "probas=Classifier.predict_proba(gdf_stats_all[column_names[0:-1]].interpolate(method='nearest'))\n",
    "gdf_stats_all[field]=predictions\n",
    "attrs_prob=['Prob_presence','Prob_absence']\n",
    "for i in range(2):\n",
    "    attr=attrs_prob[i]\n",
    "    gdf_stats_all[attr]=probas[:,i]\n",
    "\n",
    "m=gdf_stats_all.explore(column=attrs_prob[0])\n",
    "gdf_fauna.explore(m=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rasterise predictions if vector file size is too large (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_rasterised = xr_rasterize(gdf=gdf_stats_all, da=da_segments, attribute_name=attrs_prob[0])\n",
    "prob_rasterised.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remotesensingtools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
