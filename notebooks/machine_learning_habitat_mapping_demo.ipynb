{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Machine Learning for native species habitat mapping\n",
    "\n",
    "This notebook demonstrates how to load a number of Earth observation datasets using the `eo-insights` package and train a machine learning model with them. \n",
    "The purpose is to demonstrate how the `eo-insights` package can be used to support machine learning workflows.\n",
    "\n",
    "This notebook has been inspired by work conducted at FrontierSI.\n",
    "It uses a subset of species occurrence points for the Southern Bell Frog that were extracted from the Atlas of Living Australia.\n",
    "The subset has been provided in the `data` folder for the purposes of running this demonstration.\n",
    "\n",
    "## Caveats\n",
    "At this time, the `eo-insights` package focusses on data management, but it would be within scope for many of the approaches used in this notebook to become a formalised part of the package to support machine learning for Earth observation.\n",
    "\n",
    "The notebook is a demonstration only -- the model trained in this notebook should not be used for making predictions.\n",
    "It has been trained on a small subset of data and has not been fine-tuned.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. Loading a geojson of species occurrence data\n",
    "1. Querying products from Digital Earth Australia\n",
    "1. Using a subset of bands to run a segmentation algorithm\n",
    "1. Calculating zonal statistics for the segments\n",
    "1. Training a Random Forest Classifier from sklearn\n",
    "1. Performing a prediction on a larger region\n",
    "1. Displaying prediction probabilities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up notebook\n",
    "\n",
    "The following cell should be uncommented and run if you installed the package in editable mode and are actively developing and testing modules. Otherwise, it can be left commented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable logging\n",
    "This will allow you to see info and warning messages from the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s | %(levelname)s : %(message)s\",\n",
    "    level=logging.INFO,\n",
    "    stream=sys.stdout,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import configuration and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from affine import Affine\n",
    "from rasterstats import zonal_stats\n",
    "from skimage.segmentation import quickshift, slic\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from eo_insights.band_indices import calculate_indices\n",
    "from eo_insights.raster_base import LoadParams, QueryParams, RasterBase\n",
    "from eo_insights.spatial import xr_rasterize, xr_vectorize\n",
    "from eo_insights.stac_configuration import de_australia_stac_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data and define study area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DIR = Path.cwd()\n",
    "DATA_PATH = CURRENT_DIR / \"data\" / \"habitat_mapping\"\n",
    "\n",
    "# relative path of training data\n",
    "gdf_fauna = gpd.read_file(\n",
    "    DATA_PATH / \"habitat_mapping_southern_bell_frog.geojson\"\n",
    ").to_crs(\"EPSG:3577\")\n",
    "bbox = gdf_fauna.to_crs(\"EPSG:4326\").total_bounds\n",
    "\n",
    "gdf_fauna.explore(column=\"year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query satellite products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get DEA configuration and list collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = de_australia_stac_config\n",
    "config.list_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DEA products of most recent year:\n",
    "* Landsat 8 & 9 yearly geomedian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_params_ls = QueryParams(\n",
    "    bbox=bbox,\n",
    "    start_date=\"2023-01-01\",\n",
    "    end_date=\"2023-12-31\",\n",
    ")\n",
    "\n",
    "# Landsat 8 & 9 yearly geomedian: load only geomedian spectral bands for now\n",
    "params_ls_8_9_gm = LoadParams(\n",
    "    crs=\"EPSG:3577\",\n",
    "    resolution=30,\n",
    "    bands=(\"blue\", \"green\", \"red\", \"nir\", \"swir_1\", \"swir_2\"),\n",
    ")\n",
    "raster_ls_8_9_gm = RasterBase.from_stac_query(\n",
    "    config=config,\n",
    "    collections=[\"ga_ls8cls9c_gm_cyear_3\"],\n",
    "    query_params=query_params_ls,\n",
    "    load_params=params_ls_8_9_gm,\n",
    ")\n",
    "\n",
    "# calculate indices\n",
    "ds_ls_8_9_gm = calculate_indices(raster_ls_8_9_gm.data, [\"ndvi\", \"ndwi\"])\n",
    "\n",
    "ds_ls_8_9_gm = ds_ls_8_9_gm.isel(time=0)\n",
    "ds_ls_8_9_gm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sentinel-2 Barest Earth\n",
    "* Calculate BSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_params_s2_be = QueryParams(\n",
    "    bbox=bbox,\n",
    "    start_date=\"2017-01-01\",\n",
    "    end_date=\"2018-12-31\",\n",
    ")\n",
    "\n",
    "# load only bands that are used for BSI calculation\n",
    "params_s2_be = LoadParams(\n",
    "    crs=\"EPSG:3577\",\n",
    "    resolution=30,\n",
    "    bands=(\"blue\", \"red\", \"nir\", \"swir_1\"),\n",
    ")\n",
    "raster_s2_be = RasterBase.from_stac_query(\n",
    "    config=config,\n",
    "    collections=[\"s2_barest_earth\"],\n",
    "    query_params=query_params_s2_be,\n",
    "    load_params=params_s2_be,\n",
    ")\n",
    "\n",
    "# calculate BSI\n",
    "ds_s2_be_bsi = calculate_indices(raster_s2_be.data, [\"bsi\"])\n",
    "\n",
    "# dropping original bands\n",
    "ds_s2_be_bsi = ds_s2_be_bsi[[\"bsi\"]].isel(time=0)\n",
    "ds_s2_be_bsi\n",
    "# ds_s2_be_bsi['bsi'].plot.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SRTM 1 second DEM version 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_params_dem = QueryParams(\n",
    "    bbox=bbox,\n",
    "    start_date=\"2014-01-01\",\n",
    "    end_date=\"2014-12-31\",\n",
    ")\n",
    "\n",
    "params_dem = LoadParams(\n",
    "    crs=\"EPSG:3577\",\n",
    "    resolution=30,\n",
    "    bands=(\"dem\"),\n",
    ")\n",
    "raster_dem = RasterBase.from_stac_query(\n",
    "    config=config,\n",
    "    collections=[\"ga_srtm_dem1sv1_0\"],\n",
    "    query_params=query_params_dem,\n",
    "    load_params=params_dem,\n",
    ")\n",
    "ds_dem = raster_dem.data.isel(time=0)\n",
    "ds_dem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Multi-scale Topographic Position Index (TPI) layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_params_tpi = QueryParams(\n",
    "    bbox=bbox,\n",
    "    start_date=\"2018-01-01\",\n",
    "    end_date=\"2018-12-31\",\n",
    ")\n",
    "\n",
    "params_tpi = LoadParams(\n",
    "    crs=\"EPSG:3577\",\n",
    "    resolution=30,\n",
    "    bands=(\"regional\", \"intermediate\", \"local\"),\n",
    ")\n",
    "raster_tpi = RasterBase.from_stac_query(\n",
    "    config=config,\n",
    "    collections=[\"multi_scale_topographic_position\"],\n",
    "    query_params=query_params_tpi,\n",
    "    load_params=params_tpi,\n",
    ")\n",
    "ds_tip = raster_tpi.data.isel(time=0)\n",
    "ds_tip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Weathering Intensity layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_params_weathering = QueryParams(\n",
    "    bbox=bbox,\n",
    "    start_date=\"2018-01-01\",\n",
    "    end_date=\"2018-12-31\",\n",
    ")\n",
    "\n",
    "params_weathering = LoadParams(\n",
    "    crs=\"EPSG:3577\",\n",
    "    resolution=30,\n",
    "    bands=(\"intensity\"),\n",
    ")\n",
    "raster_weathering = RasterBase.from_stac_query(\n",
    "    config=config,\n",
    "    collections=[\"weathering_intensity\"],\n",
    "    query_params=query_params_weathering,\n",
    "    load_params=params_weathering,\n",
    ")\n",
    "ds_weathering = raster_weathering.data.isel(time=0)\n",
    "ds_weathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack all product bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all = xr.merge(\n",
    "    [ds_ls_8_9_gm, ds_s2_be_bsi, ds_dem, ds_tip, ds_weathering], compat=\"override\"\n",
    ").compute()\n",
    "ds_all.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object-based classification for species habitat prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_data = np.moveaxis(ds_all[[\"ndvi\", \"ndwi\", \"dem\"]].to_array().to_numpy(), 0, -1)\n",
    "\n",
    "# feature normalisation\n",
    "rows, columns, n_band = arr_data.shape\n",
    "arr_data = np.reshape(arr_data, (rows * columns, n_band))\n",
    "arr_data = StandardScaler().fit_transform(arr_data)\n",
    "\n",
    "# Do segmentation - slic or quickshift\n",
    "arr_data = np.reshape(arr_data, (rows, columns, n_band))\n",
    "# da_segments = slic(arr_data,n_segments=500,compactness=compactness,slic_zero=False)\n",
    "# da_segments = quickshift(arr_data,ratio=0.8,kernel_size=2,max_dist=10,sigma=0,convert2lab=False)\n",
    "da_segments = quickshift(\n",
    "    arr_data, ratio=1.0, kernel_size=3, max_dist=10, sigma=0, convert2lab=False\n",
    ")\n",
    "da_segments = xr.DataArray(\n",
    "    da_segments, coords=ds_all.coords, dims=ds_all.dims, attrs=ds_all.attrs\n",
    ").astype(np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorise segmentation raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_segments = xr_vectorize(da_segments).drop([\"attribute\"], axis=1)\n",
    "gdf_segments.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object-level features calculation through zonal statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = list(ds_all.keys())\n",
    "list_stats = [\"median\", \"std\", \"percentile_10\", \"percentile_90\"]\n",
    "transform = Affine.translation(\n",
    "    float(da_segments.x.min()), float(da_segments.y.max())\n",
    ") * Affine.scale(30, -30)\n",
    "# transform = segments.rio.transform() # when rioxarray is available\n",
    "gdf_stats_all = None\n",
    "attr_fields = [\"geometry\"]\n",
    "\n",
    "# Calculate zonal statistics for all bands\n",
    "for var in var_names:\n",
    "\n",
    "    print(\"calculating zonal statistics for band\", var)\n",
    "    band = ds_all[var].to_numpy()\n",
    "    zonestats = zonal_stats(\n",
    "        gdf_segments,\n",
    "        band,\n",
    "        stats=list_stats,\n",
    "        affine=transform,\n",
    "        all_touched=True,\n",
    "        geojson_out=True,\n",
    "    )\n",
    "\n",
    "    # convert to geopandas dataframe\n",
    "    gdf_stats = gpd.GeoDataFrame.from_features(zonestats, crs=gdf_segments.crs)\n",
    "\n",
    "    # rename stats to use band name as prefix\n",
    "    for stat in list_stats:\n",
    "        stat_var = var + \"_\" + stat\n",
    "        gdf_stats.rename(columns={stat: stat_var}, inplace=True)\n",
    "        attr_fields.append(stat_var)\n",
    "\n",
    "    # append statistics\n",
    "    if gdf_stats_all is None:\n",
    "        gdf_stats_all = gdf_stats.copy()\n",
    "    else:\n",
    "        gdf_stats_all = pd.concat(\n",
    "            [gdf_stats_all, gdf_stats.drop([\"geometry\"], axis=1)], axis=1\n",
    "        )\n",
    "\n",
    "# remove redundant attributes\n",
    "for column_name in list(gdf_stats.columns):\n",
    "    if column_name not in attr_fields:\n",
    "        gdf_stats_all.drop([column_name], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export zonal statistics as a vector file for reuse (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_stats_all.to_file(DATA_PATH / \"habitat_mapping_segmentation_stats.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = \"Presence\"\n",
    "n_absence = 100\n",
    "\n",
    "# Get presence samples and pesudo-absence samples\n",
    "occurence_segs = gdf_stats_all[\n",
    "    gdf_stats_all.intersects(gdf_fauna.unary_union)\n",
    "].reset_index(drop=True)\n",
    "absence_segs = (\n",
    "    pd.concat([gdf_stats_all, occurence_segs])\n",
    "    .drop_duplicates(keep=False)\n",
    "    .sample(n=n_absence)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Presence samples labelled as 1; pesudo-absence samples labelled as 2\n",
    "occurence_segs[field] = 1\n",
    "absence_segs[field] = 2\n",
    "\n",
    "# Merge presence and absence samples\n",
    "train_segs = pd.concat([occurence_segs, absence_segs]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_segs = train_segs.drop(columns=[\"geometry\"])\n",
    "column_names = train_segs.columns\n",
    "X = train_segs.iloc[:, 0:-1]\n",
    "y = train_segs.iloc[:, -1]\n",
    "Classifier = RandomForestClassifier(n_estimators=200)\n",
    "Classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(\n",
    "    n_splits=5, shuffle=True, random_state=1\n",
    ")  # stratified K-fold splitting\n",
    "overall_acc = cross_val_score(Classifier, X, y, cv=skf, scoring=\"accuracy\")\n",
    "print(\"Overall accuracy from cv scores: \", np.mean(overall_acc))\n",
    "f1_macro = cross_val_score(Classifier, X, y, cv=skf, scoring=\"f1_macro\")\n",
    "print(\"f1_macro from cv scores: \", np.mean(f1_macro))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on all the study area\n",
    "Here we predict and display prediction probability of  Bell Frog along with training points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Classifier.predict(\n",
    "    gdf_stats_all[column_names[0:-1]].interpolate(method=\"nearest\")\n",
    ")\n",
    "probas = Classifier.predict_proba(\n",
    "    gdf_stats_all[column_names[0:-1]].interpolate(method=\"nearest\")\n",
    ")\n",
    "gdf_stats_all[field] = predictions\n",
    "attrs_prob = [\"Prob_presence\", \"Prob_absence\"]\n",
    "for i in range(2):\n",
    "    attr = attrs_prob[i]\n",
    "    gdf_stats_all[attr] = probas[:, i]\n",
    "\n",
    "m = gdf_stats_all.explore(column=attrs_prob[0])\n",
    "gdf_fauna.explore(m=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rasterise predictions if vector file size is too large (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_rasterised = xr_rasterize(\n",
    "    gdf=gdf_stats_all, da=da_segments, attribute_name=attrs_prob[0]\n",
    ")\n",
    "prob_rasterised.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remotesensingtools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
